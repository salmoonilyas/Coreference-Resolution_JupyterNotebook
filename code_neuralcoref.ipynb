{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coreference using \"neuralcoref\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeuralCoref is a pipeline extension for spaCy 2.1+ which annotates and resolves coreference clusters using a neural network. NeuralCoref is production-ready, integrated in spaCy's NLP pipeline and extensible to new training datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4>#Setup:</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup/Prerequisites:\n",
    "\n",
    "#Setup VEnv.\n",
    "    #C:\\Users\\Jim>python -m venv c:\\mypvenv\n",
    "    #C:\\Users\\Jim>C:\\mypvenv\\Scripts\\activate.bat\n",
    "\n",
    "#Install Required Packages:\n",
    "    #neuralcoref (req.spacy<3.0.0,>=2.1.0)\n",
    "        #(mypvenv) C:\\Users>git clone https://github.com/huggingface/neuralcoref.git\n",
    "        #(mypvenv) C:\\Users>cd neuralcoref\n",
    "        \n",
    "        #install requirements\n",
    "        #(mypvenv) C:\\Users\\neuralcoref>pip install -r requirements.txt\n",
    "        \n",
    "        #Compile and install neuralcoref\n",
    "        #(mypvenv) C:\\Users\\neuralcoref>pip install -e .\n",
    "\n",
    "##################################\n",
    "    #Cython>=0.25\n",
    "        #pip install Cython\n",
    "    #Spacy\n",
    "        #pip install spacy==2.3.9\n",
    "\n",
    "\n",
    "    # Trained Pipelines: \n",
    "        #Catalan, Chinese, Croatian, Danish, Dutch, English, Finnish, French, German,\n",
    "        #Greek, Italian, Japanese, Korean, Lithuanian, Macedonian, Multi-language, Norwegian Bokm√•l, Polish, \n",
    "        #Portuguese, Romanian, Russian, Spanish, Swedish, Ukrainian\n",
    "    \n",
    "    # Download SpaCy English model pipeline: en_core_web_sm , en_core_web_md , en_core_web_lg , en_core_web_trf\n",
    "        #python -m spacy download en_core_web_sm\n",
    "\n",
    "#Setup VEnv in vscode settings.\n",
    "    #crtl+shift+p: Python: Select Interpreter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import spacy\n",
    "import neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SpaCy model (one of SpaCy English model pipelines)\n",
    "nlp_eng_pipeline = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x234d52e41f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding NeuralCoref to the pipe of an English SpaCy Language\n",
    "neuralcoref.add_to_pipe(nlp_eng_pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Using NeuralCoref</h4>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>List of the annotations:</h1>\n",
    "<table>\n",
    "<tr> <th> S.No </th> <th> Attribute </th> <th> Type </th> <th> Description </th> </tr>\n",
    "<tr> <td> 01 </td> <td> doc._.has_coref </td> <td> boolean</td> <td> Has any coreference has been resolved in the Doc </td> </tr>\n",
    "<tr> <td> 02 </td> <td> doc._.coref_clusters </td> <td> list of Cluster</td> <td> All the clusters of corefering mentions in the doc </td> </tr>\n",
    "<tr> <td> 03 </td> <td> doc._.coref_resolved </td> <td> unicode</td> <td> Unicode representation of the doc where each corefering mention is replaced by the main mention in the associated cluster.</td> </tr>\n",
    "<tr> <td> 04 </td> <td> doc._.coref_scores </td> <td> Dict of Dict</td> <td> Scores of the coreference resolution between mentions. </td> </tr>\n",
    "<tr> <td> 05 </td> <td> span._.is_coref </td> <td> boolean</td> <td> Whether the span has at least one corefering mention </td> </tr>\n",
    "<tr> <td> 06 </td> <td> span._.coref_cluster </td> <td> Cluster</td> <td> Cluster of mentions that corefer with the span </td> </tr>\n",
    "<tr> <td> 07 </td> <td> span._.coref_scores </td> <td> Dict</td> <td> Scores of the coreference resolution of & span with other mentions (if applicable). </td> </tr>\n",
    "<tr> <td> 08 </td> <td> token._.in_coref </td> <td> boolean</td> <td> Whether the token is inside at least one corefering mention </td> </tr>\n",
    "<tr> <td> 09 </td> <td> token._.coref_clusters </td> <td> list of Cluster</td> <td> All the clusters of corefering mentions that contains the token </td> </tr>\n",
    "\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example.\n",
    "doc_eng = nlp_eng_pipeline('Jane Jackson has a dog. She loves him.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jane Jackson: [Jane Jackson, She, him]]\n"
     ]
    }
   ],
   "source": [
    "#Print all the clusters of corefering mentions in the doc.\n",
    "if(doc_eng._.has_coref): #Has any coreference has been resolved in the Doc\n",
    "    print(doc_eng._.coref_clusters) #All the clusters of corefering mentions in the doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jane Jackson has a dog. Jane Jackson loves Jane Jackson.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Each corefering mention is replaced by the main mention in the associated cluster.\n",
    "doc_eng._.coref_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Jane Jackson: {Jane Jackson: 1.5842124223709106},\n",
       " a dog: {a dog: 1.757738709449768, Jane Jackson: -2.28167462348938},\n",
       " She: {She: -0.10834205150604248,\n",
       "  Jane Jackson: 7.760324478149414,\n",
       "  a dog: -1.3071657419204712},\n",
       " him: {him: -1.870743989944458,\n",
       "  Jane Jackson: 2.8315646648406982,\n",
       "  a dog: 2.6815736293792725,\n",
       "  She: -3.1379528045654297}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scores of the coreference resolution between mentions.\n",
    "doc_eng._.coref_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jane Jackson\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span = doc_eng[0:2]\n",
    "print(span)\n",
    "span._.is_coref #Whether the span has at least one corefering mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jane Jackson: [Jane Jackson, She, him]\n"
     ]
    }
   ],
   "source": [
    "print(span._.coref_cluster) #Cluster of mentions that corefer with the span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Jane Jackson: 1.5842124223709106}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span._.coref_scores #Scores of the coreference resolution of & span with other mentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jackson\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Jane Jackson: [Jane Jackson, She, him]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = doc_eng[1]\n",
    "print(token)\n",
    "print(token._.in_coref) #Whether the token is inside at least one corefering mention\n",
    "token._.coref_clusters #All the clusters of corefering mentions that contains the token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cluster</h4>\n",
    "A Cluster is a cluster of coreferring mentions which has 3 attributes and a few methods to simplify the navigation inside a cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>Attribute or method </td>\n",
    "        <td>Type / Return type </td>\n",
    "        <td>Description</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>i </td>\n",
    "        <td>int </td>\n",
    "        <td>Index of the cluster in the Doc</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>main </td>\n",
    "        <td>Span </td>\n",
    "        <td>Span of the most representative mention in the cluster</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>mentions </td>\n",
    "        <td>list of Span </td>\n",
    "        <td>List of all the mentions in the cluster</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>__getitem__ </td>\n",
    "        <td>return Span </td>\n",
    "        <td>Access a mention in the cluster</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>__iter__ </td>\n",
    "        <td>yields Span </td>\n",
    "        <td>Iterate over mentions in the cluster</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>__len__ </td>\n",
    "        <td>return int </td>\n",
    "        <td>Number of mentions in the cluster</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jane Jackson: [Jane Jackson, She, him]]\n",
      "[Jane Jackson, She, him]\n",
      "him\n",
      "Jane Jackson\n",
      "\n",
      "8\n",
      "9\n",
      "\n",
      "Jane Jackson\n",
      "Jane Jackson\n",
      "Jane Jackson: [Jane Jackson, She, him]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_eng_pipeline(u'Jane Jackson has a dog. She loves him.')\n",
    "\n",
    "print(doc._.coref_clusters)\n",
    "print(doc._.coref_clusters[0].mentions)\n",
    "print(doc._.coref_clusters[0].mentions[-1])\n",
    "print(doc._.coref_clusters[0].mentions[-1]._.coref_cluster.main)\n",
    "\n",
    "print()\n",
    "#mentions are spaCy Span objects which means you can access all the usual Span attributes like \n",
    "# span.start (index of the first token of the span in the document), \n",
    "# span.end (index of the first token after the span in the document)\n",
    "print(doc._.coref_clusters[0].mentions[-1].start)\n",
    "print(doc._.coref_clusters[0].mentions[-1].end)\n",
    "print()\n",
    "\n",
    "span = doc[0:2]\n",
    "print(span)\n",
    "span._.is_coref\n",
    "print(span._.coref_cluster.main)\n",
    "print(span._.coref_cluster.main._.coref_cluster)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Parameters</h4>\n",
    "#Can pass several additional parameters to neuralcoref.add_to_pipe or NeuralCoref() to control the behavior of NeuralCoref."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Full list of parameters:</h1>\n",
    "<table>\n",
    "<tr> <th> S.No </th> <th> Parameter </th> <th> Type </th> <th> Description </th> </tr>\n",
    "<tr> <td> 01 </td> <td> greedyness </td> <td> float</td> <td> A number between 0 and 1 determining how greedy the model is about making coreference decisions (more greedy means more coreference links). The default value is 0.5.  </td> </tr>\n",
    "<tr> <td> 02 </td> <td> max_dist </td> <td> int </td> <td> How many mentions back to look when considering possible antecedents of the current mention. Decreasing the value will cause the system to run faster but less accurately. The default value is 50.  </td> </tr>\n",
    "<tr> <td> 03 </td> <td> max_dist_match </td> <td> int</td> <td> The system will consider linking the current mention to a preceding one further than max_dist away if they share a noun or proper noun. In this case, it looks max_dist_match away instead. The default value is 500.  </td> </tr>\n",
    "<tr> <td> 04 </td> <td> blacklist </td> <td> boolean</td> <td> Should the system resolve coreferences for pronouns in the following list: [\"i\", \"me\", \"my\", \"you\", \"your\"]. The default value is True (coreference resolved). </td> </tr>\n",
    "<tr> <td> 05 </td> <td> store_scores </td> <td> boolean</td> <td> Should the system store the scores for the coreferences in annotations. The default value is True.  </td> </tr>\n",
    "<tr> <td> 06 </td> <td> conv_dict </td> <td> dict(str, list(str))</td> <td> A conversion dictionary that you can use to replace the embeddings of rare words (keys) by an average of the embeddings of a list of common words (values). Ex: conv_dict={\"Angela\": [\"woman\", \"girl\"]} will help resolving coreferences for Angela by using the embeddings for the more common woman and girl instead of the embedding of Angela. This currently only works for single words (not for words groups).  </td> </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x234d52e41f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Three methods for Changing the parameters\n",
    "nlp_eng_pipeline.remove_pipe(\"neuralcoref\")\n",
    "neuralcoref.add_to_pipe(nlp_eng_pipeline, greedyness=0.5, max_dist=50,\n",
    "                        max_dist_match=500,blacklist=True,store_scores=True,conv_dict={'Angela': ['woman'],'James': ['him']})\n",
    "\n",
    "#nlp_eng_lg.remove_pipe(\"neuralcoref\")  # This remove the current neuralcoref instance from SpaCy pipe\n",
    "#coref = neuralcoref.NeuralCoref(nlp_eng_lg.vocab, greedyness=0.60)\n",
    "#nlp_eng_lg.add_pipe(coref, name='neuralcoref')\n",
    "\n",
    "\n",
    "#After NeuralCoref is already in SpaCy's pipe, by modifying NeuralCoref in the pipeline\n",
    "#nlp_eng.get_pipe('neuralcoref').set_conv_dict({'Angela': ['woman'],'James': ['him']})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1: Greedyness parameter: <br>\n",
    "A number between 0 and 1 determining how greedy the model is about making coreference decisions (more greedy means more coreference links). The default value is 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jane: [Jane, She], a dog: [a dog, him]]\n",
      "Jane has a dog. Jane loves a dog.\n"
     ]
    }
   ],
   "source": [
    "#Changing the greedyness parameter\n",
    "nlp_eng_pipeline.remove_pipe(\"neuralcoref\")\n",
    "neuralcoref.add_to_pipe(nlp_eng_pipeline, greedyness=0.5) #Try:0.90, 0.30\n",
    "\n",
    "Test_Sentence='Jane has a dog. She loves him.'\n",
    "print(str(nlp_eng_pipeline(Test_Sentence)._.coref_clusters) +\"\\n\"+str(nlp_eng_pipeline(Test_Sentence)._.coref_resolved))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2: max_dist: <br>\n",
    "How many mentions back to look when considering possible antecedents of the current mention. Decreasing the value will cause the system to run faster but less accurately. The default value is 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jane: [Jane, She], a dog: [a dog, him]]\n",
      "Jane has a dog. Jane loves a dog, but the dog does not like her.\n"
     ]
    }
   ],
   "source": [
    "nlp_eng_pipeline.remove_pipe(\"neuralcoref\")\n",
    "neuralcoref.add_to_pipe(nlp_eng_pipeline, max_dist=2) #Try: 2 , 3\n",
    "\n",
    "Test_Sentence='Jane has a dog. She loves him, but the dog does not like her.'\n",
    "print(str(nlp_eng_pipeline(Test_Sentence)._.coref_clusters) +\"\\n\"+str(nlp_eng_pipeline(Test_Sentence)._.coref_resolved))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. max_dist_match <br>\n",
    "The system will consider linking the current mention to a preceding one further than max_dist away if they share a noun or proper noun. In this case, it looks max_dist_match away instead. The default value is 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jane: [Jane, Jane, her, her], a dog: [a dog, him, the dog, he]]\n",
      "Marry and her sister, Jane has a dog. Jane loves a dog, but a dog does not like Jane, a dog likes Jane sister.\n"
     ]
    }
   ],
   "source": [
    "nlp_eng_pipeline.remove_pipe(\"neuralcoref\")\n",
    "neuralcoref.add_to_pipe(nlp_eng_pipeline, max_dist_match=10) \n",
    "\n",
    "Test_Sentence='Marry and her sister, Jane has a dog. Jane loves him, but the dog does not like her, he likes her sister.'\n",
    "print(str(nlp_eng_pipeline(Test_Sentence)._.coref_clusters) +\"\\n\"+str(nlp_eng_pipeline(Test_Sentence)._.coref_resolved))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4. Blacklist <br>\n",
    "Should the system resolve coreferences for pronouns in the following list: [\"i\", \"me\", \"my\", \"you\", \"your\"]. The default value is True (coreference resolved)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[John: [John, He, his, he]]\n",
      "John is an engineer. John loves John job, and John is very dedicated.\n",
      "\n",
      "[]\n",
      "I am John and I am an engineer. My friend Mike and I work in Microsoft\n"
     ]
    }
   ],
   "source": [
    "nlp_eng_pipeline.remove_pipe(\"neuralcoref\") # Remove the current neuralcoref instance from SpaCy pipe\n",
    "neuralcoref.add_to_pipe(nlp_eng_pipeline, blacklist=True) #Try:False\n",
    "\n",
    "Test_Sentence='John is an engineer. He loves his job, and he is very dedicated.'\n",
    "print(str(nlp_eng_pipeline(Test_Sentence)._.coref_clusters) +\"\\n\"+str(nlp_eng_pipeline(Test_Sentence)._.coref_resolved))\n",
    "print()\n",
    "\n",
    "Test_Sentence='I am John and I am an engineer. My friend Mike and I work in Microsoft'\n",
    "print(str(nlp_eng_pipeline(Test_Sentence)._.coref_clusters) +\"\\n\"+str(nlp_eng_pipeline(Test_Sentence)._.coref_resolved))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5. store_scores <br>\n",
    "Should the system store the scores for the coreferences in annotations. The default value is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x234d52e41f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_eng_pipeline.remove_pipe(\"neuralcoref\")\n",
    "neuralcoref.add_to_pipe(nlp_eng_pipeline, store_scores=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6: Conversion dictionary parameter to help resolve rare words <br>\n",
    "\n",
    "#A conversion dictionary that you can use to replace the embeddings of rare words (keys) by an average of the embeddings of a list of common words (values). Ex: conv_dict={\"Angela\": [\"woman\", \"girl\"]} will help resolving coreferences for Angela by using the embeddings for the more common woman and girl instead of the embedding of Angela. This currently only works for single words (not for words groups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Deepika: [Deepika, She, him, The movie star]]\n",
      "Deepika has a dog. Deepika loves Deepika. Deepika has always been fond of animals\n"
     ]
    }
   ],
   "source": [
    "Test_Sentence='Deepika has a dog. She loves him. The movie star has always been fond of animals'\n",
    "print(str(nlp_eng_pipeline(Test_Sentence)._.coref_clusters) +\"\\n\"+str(nlp_eng_pipeline(Test_Sentence)._.coref_resolved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Deepika: [Deepika, She, The movie star], a dog: [a dog, him]]\n",
      "Deepika has a dog. Deepika loves a dog. Deepika has always been fond of animals\n"
     ]
    }
   ],
   "source": [
    "nlp_eng_pipeline.remove_pipe(\"neuralcoref\")\n",
    "neuralcoref.add_to_pipe(nlp_eng_pipeline, conv_dict={'Deepika': ['her'],'dog': ['him']}) #try: girl, her, actress\n",
    "\n",
    "Test_Sentence='Deepika has a dog. She loves him. The movie star has always been fond of animals'\n",
    "print(str(nlp_eng_pipeline(Test_Sentence)._.coref_clusters) +\"\\n\"+str(nlp_eng_pipeline(Test_Sentence)._.coref_resolved))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comparision</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[he: [he, his], he was very busy with his work: [he was very busy with his work, it], Peter: [Peter, He, his], He and his wife: [He and his wife, they, They, they]]\n",
      "Although he was very busy with he work, Peter had enough of he was very busy with his work. Peter and Peter wife decided He and his wife needed a holiday. He and his wife travelled to Spain because He and his wife loved the country very much.\n"
     ]
    }
   ],
   "source": [
    "Test_Sentence='Although he was very busy with his work, Peter had enough of it. He and his wife decided they needed a holiday. They travelled to Spain because they loved the country very much.'\n",
    "print(str(nlp_eng_pipeline(Test_Sentence)._.coref_clusters) +\"\\n\"+str(nlp_eng_pipeline(Test_Sentence)._.coref_resolved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The woman: [The woman, She, her]]\n",
      "The woman looked down and saw Lesley. The woman stood up and greeted The woman.\n"
     ]
    }
   ],
   "source": [
    "Test_Sentence='The woman looked down and saw Lesley. She stood up and greeted her.'\n",
    "print(str(nlp_eng_pipeline(Test_Sentence)._.coref_clusters) +\"\\n\"+str(nlp_eng_pipeline(Test_Sentence)._.coref_resolved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The woman: [The woman, She]]\n",
      "The woman looked down and saw Lesley. The woman stood up and greeted him.\n"
     ]
    }
   ],
   "source": [
    "Test_Sentence='The woman looked down and saw Lesley. She stood up and greeted him.'\n",
    "print(str(nlp_eng_pipeline(Test_Sentence)._.coref_clusters) +\"\\n\"+str(nlp_eng_pipeline(Test_Sentence)._.coref_resolved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[David: [David, he]]\n",
      "David advised Jim that David must study\n"
     ]
    }
   ],
   "source": [
    "Test_Sentence='David advised Jim that he must study'\n",
    "print(str(nlp_eng_pipeline(Test_Sentence)._.coref_clusters) +\"\\n\"+str(nlp_eng_pipeline(Test_Sentence)._.coref_resolved))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09a3aca63b41b545038eab68a7f04632e806cd5402abe3c49a4ef06483ec71b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
